{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f101e66c",
   "metadata": {},
   "source": [
    "### ğŸš© Import libraries & packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f95777bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data tools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# import visual tools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "\n",
    "# import util tools\n",
    "import os\n",
    "from os.path import join    # define route of files\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# import data pre-processing tools\n",
    "import missingno as msno    # check missing data\n",
    "\n",
    "\n",
    "# import ML tools 1\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "# import ML tools 2\n",
    "import sklearn.ensemble as ensemble\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "    # XGBM (extreme GBM), LGBM (lighting GBM) :\n",
    "    # gradient boosting machine (GBM) ì•Œê³ ë¦¬ì¦˜ ê³„ì—´ì˜ ë³€í˜•\n",
    "    # ê°ê° ë…ìì ì¸ ì˜¤í”ˆ ì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜•íƒœë¡œ í•´ë‹¹ ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ :D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a6b744",
   "metadata": {},
   "source": [
    "### ğŸš© Define constants (hyper params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82d58f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2023\n",
    "\n",
    "TEST_SIZE = 0.2    # train/test split ratio for train_test_split()\n",
    "CV_SIZE = 5        # cross validation size\n",
    "\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8585372",
   "metadata": {},
   "source": [
    "### ğŸš© Load data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a2aafb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20140627T000000</td>\n",
       "      <td>257500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3097</td>\n",
       "      <td>-122.327</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20150115T000000</td>\n",
       "      <td>291850.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1060</td>\n",
       "      <td>9711</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98198</td>\n",
       "      <td>47.4095</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>1650</td>\n",
       "      <td>9711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>20140527T000000</td>\n",
       "      <td>468000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1160</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>860</td>\n",
       "      <td>300</td>\n",
       "      <td>1942</td>\n",
       "      <td>0</td>\n",
       "      <td>98115</td>\n",
       "      <td>47.6900</td>\n",
       "      <td>-122.292</td>\n",
       "      <td>1330</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15025</th>\n",
       "      <td>15025</td>\n",
       "      <td>20150421T000000</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.25</td>\n",
       "      <td>3410</td>\n",
       "      <td>10125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>3410</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>98040</td>\n",
       "      <td>47.5653</td>\n",
       "      <td>-122.223</td>\n",
       "      <td>2290</td>\n",
       "      <td>10125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15026</th>\n",
       "      <td>15026</td>\n",
       "      <td>20140915T000000</td>\n",
       "      <td>810000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3990</td>\n",
       "      <td>7838</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>3990</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>98053</td>\n",
       "      <td>47.6857</td>\n",
       "      <td>-122.046</td>\n",
       "      <td>3370</td>\n",
       "      <td>6814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15030</th>\n",
       "      <td>15030</td>\n",
       "      <td>20141014T000000</td>\n",
       "      <td>610685.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2520</td>\n",
       "      <td>6023</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2520</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98056</td>\n",
       "      <td>47.5137</td>\n",
       "      <td>-122.167</td>\n",
       "      <td>2520</td>\n",
       "      <td>6023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15031</th>\n",
       "      <td>15031</td>\n",
       "      <td>20150326T000000</td>\n",
       "      <td>1007500.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3510</td>\n",
       "      <td>7200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2600</td>\n",
       "      <td>910</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5537</td>\n",
       "      <td>-122.398</td>\n",
       "      <td>2050</td>\n",
       "      <td>6200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>15034</td>\n",
       "      <td>20141015T000000</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10537 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id             date      price  bedrooms  bathrooms  sqft_living  \\\n",
       "0          0  20141013T000000   221900.0         3       1.00         1180   \n",
       "1          1  20150225T000000   180000.0         2       1.00          770   \n",
       "3          3  20140627T000000   257500.0         3       2.25         1715   \n",
       "4          4  20150115T000000   291850.0         3       1.50         1060   \n",
       "6          6  20140527T000000   468000.0         2       1.00         1160   \n",
       "...      ...              ...        ...       ...        ...          ...   \n",
       "15025  15025  20150421T000000  1575000.0         4       3.25         3410   \n",
       "15026  15026  20140915T000000   810000.0         4       3.00         3990   \n",
       "15030  15030  20141014T000000   610685.0         4       2.50         2520   \n",
       "15031  15031  20150326T000000  1007500.0         4       3.50         3510   \n",
       "15034  15034  20141015T000000   325000.0         2       0.75         1020   \n",
       "\n",
       "       sqft_lot  floors  waterfront  view  ...  grade  sqft_above  \\\n",
       "0          5650     1.0           0     0  ...      7        1180   \n",
       "1         10000     1.0           0     0  ...      6         770   \n",
       "3          6819     2.0           0     0  ...      7        1715   \n",
       "4          9711     1.0           0     0  ...      7        1060   \n",
       "6          6000     1.0           0     0  ...      7         860   \n",
       "...         ...     ...         ...   ...  ...    ...         ...   \n",
       "15025     10125     2.0           0     0  ...     10        3410   \n",
       "15026      7838     2.0           0     0  ...      9        3990   \n",
       "15030      6023     2.0           0     0  ...      9        2520   \n",
       "15031      7200     2.0           0     0  ...      9        2600   \n",
       "15034      1076     2.0           0     0  ...      7        1020   \n",
       "\n",
       "       sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0                  0      1955             0    98178  47.5112 -122.257   \n",
       "1                  0      1933             0    98028  47.7379 -122.233   \n",
       "3                  0      1995             0    98003  47.3097 -122.327   \n",
       "4                  0      1963             0    98198  47.4095 -122.315   \n",
       "6                300      1942             0    98115  47.6900 -122.292   \n",
       "...              ...       ...           ...      ...      ...      ...   \n",
       "15025              0      2007             0    98040  47.5653 -122.223   \n",
       "15026              0      2003             0    98053  47.6857 -122.046   \n",
       "15030              0      2014             0    98056  47.5137 -122.167   \n",
       "15031            910      2009             0    98136  47.5537 -122.398   \n",
       "15034              0      2008             0    98144  47.5941 -122.299   \n",
       "\n",
       "       sqft_living15  sqft_lot15  \n",
       "0               1340        5650  \n",
       "1               2720        8062  \n",
       "3               2238        6819  \n",
       "4               1650        9711  \n",
       "6               1330        6000  \n",
       "...              ...         ...  \n",
       "15025           2290       10125  \n",
       "15026           3370        6814  \n",
       "15030           2520        6023  \n",
       "15031           2050        6200  \n",
       "15034           1020        1357  \n",
       "\n",
       "[10537 rows x 21 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define routes of data(.csv) files\n",
    "data_dir = \"~/aiffel/kaggle_kakr_housing/data/\"\n",
    "\n",
    "\n",
    "# load csv files -> pd.DataFrame\n",
    "train_data = pd.read_csv(join(data_dir, \"train.csv\"))\n",
    "test_data = pd.read_csv(join(data_dir, \"test.csv\"))\n",
    "\n",
    "\n",
    "train_data = train_data.loc[train_data['id']!=8912]\n",
    "train_data = train_data.loc[train_data['id']!=2302]\n",
    "train_data = train_data.loc[train_data['id']!=4123]\n",
    "\n",
    "#train_data.loc[train_data['sqft_living'] > 13000]\n",
    "train_data.drop(train_data.loc[(train_data['price']>12) & (train_data['grade'] == 3)].index, inplace=True)\n",
    "#train_data.loc[(train_data['price']>12) & (train_data['grade'] == 3)]\n",
    "train_data.drop(train_data.loc[(train_data['price']>14.7) & (train_data['grade'] == 8)].index, inplace=True)\n",
    "#train_data.loc[(train_data['price']>14.7) & (train_data['grade'] == 8)]\n",
    "train_data.drop(train_data.loc[(train_data['price']>15.5) & (train_data['grade'] == 11)].index, inplace=True)\n",
    "#train_data.loc[(train_data['price']>15.5) & (train_data['grade'] == 11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cec855",
   "metadata": {},
   "source": [
    "### ğŸš© Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ce60f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### train data pre-processing\n",
    "\n",
    "# \"date\" column format change\n",
    "train_data[\"date\"] = train_data[\"date\"].apply(lambda i: i[:6]).astype(int)\n",
    "\n",
    "# \"price\" column regularization(?) -> grow variation of \"price\" values\n",
    "train_data[\"price\"] = np.log1p(train_data[\"price\"])\n",
    "\n",
    "# \"id\" column remove\n",
    "train_data = train_data.drop(columns = [\"id\"])\n",
    "\n",
    "### test data pre-processing\n",
    "#print(train_data.loc[train_data['sqft_living'] > 13000])\n",
    "\n",
    "# \"date\" column format change\n",
    "test_data[\"date\"] = test_data[\"date\"].apply(lambda i: i[:6]).astype(int)\n",
    "\n",
    "# \"id\" column remove\n",
    "test_data = test_data.drop(columns = [\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc0cc92",
   "metadata": {},
   "source": [
    "### ğŸš© Extract feature matrices (X) & target vectors (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf60e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train data -> feature matrix (X) & target vector (y) split\n",
    "X = train_data.drop(columns = [\"price\"])    # exclude target vector column\n",
    "y = train_data[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e312d567",
   "metadata": {},
   "source": [
    "### ğŸš© Define useful methods (RMSE, cross validation, grid search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebed11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get RMSE losses from log(\"price\") values\n",
    "def getRMSE_log2exp(y_test, y_pred):\n",
    "    y_test, y_pred = np.expm1(y_test), np.expm1(y_pred)\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "\n",
    "# get cross validation scores of \"one\" learning model (for model evaluation)\n",
    "def getCVscore(X, model):\n",
    "    kfold = model_selection.KFold(n_splits = CV_SIZE).get_n_splits(X.values)\n",
    "    score = np.mean(model_selection.cross_val_score(model, X = X.values, y = y, cv = kfold))\n",
    "    print(\"CV score of\", model.__class__.__name__, \":\", score)\n",
    "    return score\n",
    "        \n",
    "    \n",
    "    \n",
    "# search best parameter values for learning models\n",
    "def searchBestParams(model, X, y, param_grid, verbose = 2, n_jobs = 5):\n",
    "    # initialize grid search model\n",
    "    grid = model_selection.GridSearchCV(model, param_grid = param_grid, \\\n",
    "                                        scoring = \"neg_mean_squared_error\", \\\n",
    "                                        cv = CV_SIZE, verbose = verbose, n_jobs = n_jobs)\n",
    "    \n",
    "    # grid search model fitting\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    # return best 5 parameter values\n",
    "    result = pd.DataFrame(grid.cv_results_[\"params\"])\n",
    "    result[\"score\"] = grid.cv_results_[\"mean_test_score\"]\n",
    "    result = result.sort_values(\"score\", ascending = False, ignore_index = True)\n",
    "    print(result.head())\n",
    "    return result.head()\n",
    "\n",
    "\n",
    "\n",
    "# save predicted \"price\" values as a submission file\n",
    "def makeSubmissionFile(y_pred):\n",
    "    data_dir = \"~/aiffel/kaggle_kakr_housing/data/\"\n",
    "    submission = pd.read_csv(join(data_dir, \"sample_submission.csv\"))\n",
    "    submission[\"price\"] = y_pred\n",
    "    submission.to_csv(join(data_dir, \"submission_new.csv\"), index = False)\n",
    "    print(\"The submission file has created succesfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d999c9b",
   "metadata": {},
   "source": [
    "### ğŸš© Generate & evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58e780aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model instances\n",
    "extreme = xgb.XGBRegressor(random_state = RANDOM_STATE)\n",
    "light = lgb.LGBMRegressor(random_state = RANDOM_STATE)\n",
    "boost = ensemble.GradientBoostingRegressor(random_state = RANDOM_STATE)\n",
    "forest = ensemble.RandomForestRegressor(random_state = RANDOM_STATE)\n",
    "\n",
    "# create my own learning model collections\n",
    "models = [extreme, light, boost, forest]\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate model performance (cross validation)\n",
    "#for model in models:\n",
    "#    score = getCVscore(X, model)\n",
    "\n",
    "# Output :\n",
    "# CV score of XGBRegressor  :  0.8973388661281285\n",
    "# CV score of LGBMRegressor  :  0.9024911910917768\n",
    "# CV score of GradientBoostingRegressor  :  0.8796312932769542\n",
    "# CV score of RandomForestRegressor : 0.8851571351312119\n",
    "\n",
    "### It seems four models provide sufficiently high performance!\n",
    "### cross validation ì‹¤í–‰ ê²°ê³¼, 4ê°œì˜ í•™ìŠµ ëª¨ë¸ì´ ì¶©ë¶„í•œ ì„±ëŠ¥ì„ ì œê³µí•œë‹¤ëŠ” ê²ƒì„ í™•ì¸\n",
    "### ê·¸ë ‡ë‹¤ë©´ í•´ë‹¹ 4ê°œì˜ í•™ìŠµ ëª¨ë¸ì„ í™œìš©í•˜ì—¬ í•™ìŠµ & ì˜ˆì¸¡ ë„ì „!!\n",
    "### ì„±ëŠ¥ í™•ì¸ì„ ë§ˆì³¤ìœ¼ë¯€ë¡œ, ì„±ëŠ¥ í‰ê°€ ê³¼ì •ì€ ì£¼ì„(#)ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ë‹¤ìŒ ì½”ë“œ ì‹¤í–‰ ë•ŒëŠ” ìƒëµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1756545b",
   "metadata": {},
   "source": [
    "### ğŸš© Search best LGBM param values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6ef20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set available values for LGBM parameters\n",
    "lgbm_param_grid = {\"max_depth\" : [-1], \\\n",
    "                    \"learning_rate\" : [0.01, 0.05, 0.1], \\\n",
    "                    \"n_estimators\" : [50, 75, 100], \\\n",
    "                    \"num_leaves\" : [26, 31, 36], \\\n",
    "                    \"boosting_type\" : [\"gbdt\"], \\\n",
    "                    \"reg_lambda\" : [30, 50, 70]}\n",
    "    # max_depth : ì˜ì‚¬ ê²°ì • ë‚˜ë¬´ì˜ ê¹Šì´, ì •ìˆ˜ ì‚¬ìš©\n",
    "    # learning_rate : í•œ ìŠ¤í…ì— ì´ë™í•˜ëŠ” ì–‘ì„ ê²°ì •í•˜ëŠ” íŒŒë¼ë¯¸í„°, ë³´í†µ 0.0001~0.1 ì‚¬ì´ì˜ ì‹¤ìˆ˜ ì‚¬ìš©\n",
    "    # n_estimators : ì‚¬ìš©í•˜ëŠ” ê°œë³„ ëª¨ë¸ì˜ ê°œìˆ˜, ë³´í†µ 50~100 ì´ìƒì˜ ì •ìˆ˜ ì‚¬ìš©\n",
    "    # num_leaves : í•˜ë‚˜ì˜ LightGBM íŠ¸ë¦¬ê°€ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ìµœëŒ€ ìì˜ ìˆ˜\n",
    "    # boosting_type : ë¶€ìŠ¤íŒ… ë°©ì‹, gbdt, rf ë“±ì˜ ë¬¸ìì—´ ì…ë ¥\n",
    "    # reg_lambda : L2 regularization term on weights\n",
    "\n",
    "    \n",
    "# Search best set of parameter values\n",
    "#print(searchBestParams(light, X, y, lgbm_param_grid, verbose = 0))\n",
    "\n",
    "# Output :\n",
    "#   boosting_type  learning_rate  max_depth  n_estimators  num_leaves  reg_lambda      score\n",
    "# 0          gbdt            0.1         -1           100          36          30  -0.026989\n",
    "# 1          gbdt            0.1         -1           100          31          30  -0.027051\n",
    "# 2          gbdt            0.1         -1           100          36          50  -0.027284\n",
    "# 3          gbdt            0.1         -1           100          26          30  -0.027552\n",
    "# 4          gbdt            0.1         -1           100          31          50  -0.027646\n",
    "\n",
    "### LGBMëŠ” learning_rate = 0.1, n_estimators = 100, num_leaves = 36, reg_lambda = 30 ì¼ ë•Œ ìµœìƒì˜ ì„±ëŠ¥ì„ì„ í™•ì¸\n",
    "### XGBM ë˜í•œ LGBMê³¼ ìœ ì‚¬í•œ GBM ê³„ì—´ì˜ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì´ë¯€ë¡œ, ìœ ì‚¬í•œ ìˆ˜ì¹˜ ëŒ€ì…í•˜ë©´ OK\n",
    "### íŒŒë¼ë¯¸í„° ê°’ë³„ ì„±ëŠ¥ í™•ì¸ì„ ë§ˆì³¤ìœ¼ë¯€ë¡œ, íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³¼ì •ì€ ì£¼ì„(#)ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ë‹¤ìŒ ì½”ë“œ ì‹¤í–‰ ë•ŒëŠ” ìƒëµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaa6e60",
   "metadata": {},
   "source": [
    "### ğŸš© Adjust XGBD & LGBD params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d84dfa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate another model instances with adjusted params\n",
    "extreme = xgb.XGBRegressor(random_state = RANDOM_STATE, learning_rate = 0.2, n_estimators = 100)\n",
    "light = lgb.LGBMRegressor(random_state = RANDOM_STATE, learning_rate = 0.1, n_estimators = 300, num_leaves = 36, reg_lambda = 30)\n",
    "\n",
    "# Update XGBD & LGBD models in my model collection\n",
    "models[0] = extreme\n",
    "models[1] = light\n",
    "\n",
    "### grid search ê²°ê³¼ ê°’ê³¼ ìœ ì‚¬í•œ ê°’ ìœ„ì£¼ë¡œ ë‹¤ì–‘í•œ ê°’ì„ ì‹œë„í•´ ë³¸ ê²°ê³¼, í•´ë‹¹ íŒŒë¼ë¯¸í„° ê°’ìœ¼ë¡œ ê²°ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ca8f0",
   "metadata": {},
   "source": [
    "### ğŸš© Perform fit() & predict() -> Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "571e3330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "for model in models :\n",
    "    # split train data -> for training & for valication\n",
    "    X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, \\\n",
    "                                        test_size = TEST_SIZE, random_state = RANDOM_STATE)\n",
    "\n",
    "    # model fitting (learning)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # predict \"price\"\n",
    "    y_pred = model.predict(X_valid)\n",
    "\n",
    "    # get error (wish less than 1.1M)\n",
    "    error = getRMSE_log2exp(y_valid, y_pred)\n",
    "    print(\"RMSE of\", model.__class__.__name__, \" : \", error)\n",
    "\"\"\"\n",
    "print('test')\n",
    "    \n",
    "# Output :\n",
    "# RMSE of XGBRegressor  :  107509.3104391456\n",
    "# RMSE of LGBMRegressor  :  104654.07159199048\n",
    "# RMSE of GradientBoostingRegressor  :  128360.19649691365\n",
    "# RMSE of RandomForestRegressor  :  125487.07102453562\n",
    "\n",
    "### XGBM, LGBM ëª¨ë¸ì´ í¬ë§ì´ ë³´ì´ë¯€ë¡œ ë‘ ê°€ì§€ ëª¨ë¸ì— ëŒ€í•˜ì—¬ ensemble ê¸°ë²•ì„ ì‹œë„í•´ë³´ì"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6eab1e",
   "metadata": {},
   "source": [
    "### ğŸš© Define ensemble system methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ba87889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create XGBM/LGBM models with random seed and fitting for EPOCHS iteration\n",
    "def getAveragingBlending(X, y, X_test, epochs, XGBM = False, LGBM = False):\n",
    "    y_preds = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        if XGBM:    # XGBM model\n",
    "            model = xgb.XGBRegressor(learning_rate = 0.2, n_estimators = 100)\n",
    "        else:      # LGBM model\n",
    "            model = lgb.LGBMRegressor(learning_rate = 0.1, n_estimators = 300, num_leaves = 36, reg_lambda = 30)\n",
    "            \n",
    "        X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size = TEST_SIZE)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_preds.append(y_pred)  # save predicted values from each model\n",
    "\n",
    "    y_preds = np.array(y_preds) \n",
    "    mean = np.mean(y_preds, axis = 0)    # get mean values of predicted values\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4740c",
   "metadata": {},
   "source": [
    "### ğŸš© Predict \"price\" with various learning ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53717ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. predict with only one XGBM\n",
    "#extreme = xgb.XGBRegressor(random_state = RANDOM_STATE, learning_rate = 0.2, n_estimators = 100)\n",
    "#extreme.fit(X, y)\n",
    "#y_pred = extreme.predict(test_data)\n",
    "\n",
    "\n",
    "# 2-1. predict with only one LGBM\n",
    "#light = lgb.LGBMRegressor(random_state = RANDOM_STATE, learning_rate = 0.1, n_estimators = 300, num_leaves = 36)\n",
    "#light.fit(X, y)\n",
    "#y_pred = light.predict(test_data)\n",
    "\n",
    "\n",
    "# 2-2. predict with only one LGBM & regularization parameter 30\n",
    "#light_reg = lgb.LGBMRegressor(random_state = RANDOM_STATE, learning_rate = 0.1, n_estimators = 300, num_leaves = 36, reg_lambda = 30)\n",
    "#light_reg.fit(X, y)\n",
    "#y_pred = light_reg.predict(test_data)\n",
    "\n",
    "\n",
    "# 2-3. predict with only one LGBM & regularization parameter 50\n",
    "light_reg = lgb.LGBMRegressor(random_state = RANDOM_STATE, learning_rate = 0.1, max_depth = -1, n_estimators = 300, num_leaves = 36, reg_lambda = 50)\n",
    "light_reg.fit(X, y)\n",
    "y_pred = light_reg.predict(test_data)\n",
    "\n",
    "\n",
    "# 3. predict with ensembled XGBMs\n",
    "#y_pred = getAveragingBlending(X, y, test_data, EPOCHS, XGBM = True)\n",
    "\n",
    "\n",
    "# 4. predict with ensembled LGBMs\n",
    "#y_pred = getAveragingBlending(X_train, y_train, X_valid, EPOCHS, LGBM = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ac8ce",
   "metadata": {},
   "source": [
    "### ğŸš© Save predicted \"price\" as submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "214748d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The submission file has created succesfully.\n"
     ]
    }
   ],
   "source": [
    "# recover original price value range\n",
    "y_pred = np.expm1(y_pred)\n",
    "\n",
    "# save as file\n",
    "makeSubmissionFile(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf6587d",
   "metadata": {},
   "source": [
    "-----\n",
    "**íšŒê³ ë¡** :  \n",
    "XGBM, LGBM ì´ ë‹¤ë¥¸ í•™ìŠµ ëª¨ë¸ì— ë¹„í•´ ì„±ëŠ¥ì´ ì¢‹ë‹¤ë˜ë°, ëª¸ì†Œ ì²´í—˜í•  ìˆ˜ ìˆì—ˆë‹¤  \n",
    "ë˜í•œ ê°™ì€ ëª¨ë¸ì´ë¼ë„ parameter ê°’ì— ë”°ë¼ì„œë„ ì¶©ë¶„íˆ ì„±ëŠ¥ì„ ì¡°ì •í•  ìˆ˜ ìˆìŒì„ ì²´ê°í–ˆë‹¤  \n",
    "ë™ì¼í•œ ëª¨ë¸ì— ì„œë¡œ ë‹¤ë¥¸ random seedë¥¼ ë¶€ì—¬í•´ì„œ ensemble ì„ ì‹œë„í•˜ì˜€ëŠ”ë°, ëŒ€ë¶€ë¶„ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šì•˜ë‹¤\n",
    "ì„œë¡œ ë‹¤ë¥¸ ëª¨ë¸ë“¤ì„ ë¬¶ì–´ì„œ ensemble ì„ í•´ì•¼ ì„±ëŠ¥ì´ í–¥ìƒë˜ëŠ”ê±¸ê¹Œ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47121b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
